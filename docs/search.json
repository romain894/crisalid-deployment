[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to CRISalid Deployment Documentation",
    "section": "",
    "text": "CRISalid is a modular set of open-source components designed to support the development of an institutional Current Research Information System (CRIS).\nIt is built to be message-oriented, modular, and loosely coupled. Each component communicates with others through asynchronous messaging (via RabbitMQ), while also exposing classical REST or GraphQL APIs to allow service-oriented approaches."
  },
  {
    "objectID": "index.html#development-test-deployment",
    "href": "index.html#development-test-deployment",
    "title": "Welcome to CRISalid Deployment Documentation",
    "section": "üß™ Development & Test Deployment",
    "text": "üß™ Development & Test Deployment\nUse this if you‚Äôre:\n\nWorking on a specific CRISalid module\nTesting integration locally\nEvaluating CRISalid for your institution\n\nWe provide:\n\nDocker Compose examples\nManual installation instructions (e.g., for deploying on virtual machines)\n\n‚Üí Explore Development & Test Deployment"
  },
  {
    "objectID": "index.html#production-deployment",
    "href": "index.html#production-deployment",
    "title": "Welcome to CRISalid Deployment Documentation",
    "section": "üöÄ Production Deployment",
    "text": "üöÄ Production Deployment\nFor institutional or production-grade deployments.\nWhile Kubernetes is the primary target, it is not required ‚Äî you may still use Docker or manual setups if needed.\nWe provide:\n\nShell scripts to generate Kubernetes manifests\nManual installation instructions for production environments\n\n‚Üí Explore Production Deployment"
  },
  {
    "objectID": "dev/dev-backend.html",
    "href": "dev/dev-backend.html",
    "title": "Using Docker Compose as Backend for Local Development",
    "section": "",
    "text": "This section explains how to use the Docker Compose stack strictly as a backend while running SoVisu+ locally  (Next.js dev server) for frontend development.\n\n\n\n\nRun all shared services (Neo4j, message bus, Keycloak, APIs, databases) in Docker, but run SoVisu+ on your host machine. To make this work, you must:\n\nMap the necessary service ports from containers to the host.\nUse a dedicated profile (e.g.¬†sovisuplus-db) to start only SoVisu+ backend services.\nPoint your local SoVisu+ to these services via env vars and /etc/hosts.\n\n\n\n\n\nAdd these entries to your /etc/hosts (if not already done in the main guide):\n127.0.0.1 sovisuplus.local\n127.0.0.1 keycloak.local\n\nSoVisu+ uses ORCID OAuth, which requires valid hostnames even for sandbox keys.\n\n\n\n\n\nYou‚Äôll run SoVisu+ locally, so your host needs to reach the containers. Make sure the following port mappings are enabled.\n\n\nUncomment the ports section so Postgres is reachable from your host:\n\n\nsovisuplus.yaml\n\nservices:\n  svp-db:\n    image: postgres:16\n    container_name: svp-db\n    restart: always\n    environment:\n      POSTGRES_USER: ${SVP_DB_USER}\n      POSTGRES_PASSWORD: ${SVP_DB_PASSWORD}\n      POSTGRES_DB: ${SVP_DB_NAME}\n    expose:\n      - 5432\n    ports:\n      - 5432:5432\n    volumes:\n      - ./postgres-data:/var/lib/postgresql/data\n    networks:\n      - svp-network\n    healthcheck:\n      test: ['CMD-SHELL', 'pg_isready -d ${SVP_DB_NAME} -U ${SVP_DB_USER}']\n      interval: 1s\n      timeout: 5s\n      retries: 10\n    command: [\"postgres\",\"-c\",\"max_connections=200\",\"-c\",\"superuser_reserved_connections=3\"]\n    profiles:\n      - sovisuplus\n      - sovisuplus-db\n\n  sovisuplus:\n    image: crisalidesr/sovisuplus:latest\n    container_name: sovisuplus\n    ports:\n      - 3000:3000\n      - 3001:3001\n    environment:\n      - DB_NAME=${SVP_DB_NAME}\n      - DB_USER=${SVP_DB_USER}\n      - DB_PASSWORD=${SVP_DB_PASSWORD}\n      - DB_HOST=svp-db\n      - DB_PORT=5432\n      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}\n      - AMQP_HOST=crisalid-bus\n      - AMQP_PORT=${CRISALID_BUS_AMQP_PORT}\n      - AMQP_USER=${CRISALID_BUS_USER}\n      - AMQP_PASSWORD=${CRISALID_BUS_PASSWORD}\n      - AMQP_QUEUE_NAME=${SVP_AMQP_QUEUE_NAME}\n      - AMQP_EXCHANGE_NAME=${SVP_AMQP_EXCHANGE_NAME}\n      - GRAPHQL_ENDPOINT_ENABLED=${GRAPHQL_ENDPOINT_ENABLED}\n      - GRAPHQL_ENDPOINT_URL=http://apollo:${APOLLO_API_PORT}/graphql\n      - GRAPHQL_API_KEY_ENABLED=${GRAPHQL_API_KEY_ENABLED}\n      - KEYCLOAK_CLIENT_ID=sovisuplus\n      - KEYCLOAK_CLIENT_SECRET=${SOVISUPLUS_KEYCLOAK_CLIENT_SECRET}\n      - KEYCLOAK_ADDR=${KEYCLOAK_SCHEME}://${KEYCLOAK_HOST}:${KEYCLOAK_PORT}\n      - KEYCLOAK_REALM=${KEYCLOAK_REALM}\n      - APP_URL=${SOVISUPLUS_SCHEME}://${SOVISUPLUS_HOST}:${SOVISUPLUS_PORT}\n      - ORCID_URL=${ORCID_URL}\n      - ORCID_SCOPES=${ORCID_SCOPES}\n      - ORCID_CLIENT_ID=${ORCID_CLIENT_ID}\n      - ORCID_CLIENT_SECRET=${ORCID_CLIENT_SECRET}\n      - SOVISUPLUS_HOST=${SOVISUPLUS_SCHEME}://${SOVISUPLUS_HOST}:${SOVISUPLUS_PORT}\n    depends_on:\n      svp-db:\n        condition: service_healthy\n      crisalid-bus:\n        condition: service_healthy\n    networks:\n      - svp-network\n      - crisalid-front\n    profiles:\n      - sovisuplus\n\nnetworks:\n  svp-network:\n    driver: bridge\n  crisalid-front:\n    driver: bridge\n\nservices:\n  svp-db:\n    image: postgres:16\n    container_name: svp-db\n    restart: always\n    environment:\n      POSTGRES_USER: ${SVP_DB_USER}\n      POSTGRES_PASSWORD: ${SVP_DB_PASSWORD}\n      POSTGRES_DB: ${SVP_DB_NAME}\n    expose:\n      - 5432\n    ports:\n      - 5432:5432\n\n\n\nEnsure the public mapping is present (it typically is already because Apollo graphql GUI is one of the main user interfaces):\n\n\napollo.yaml\n\nservices:\n  apollo:\n    image: crisalidesr/crisalid-apollo:latest\n    ports:\n      - ${APOLLO_API_PORT}:4000\n    depends_on:\n      neo4j:\n        condition: service_healthy\n    environment:\n      - APP_ENV=DEV\n      - NEO4J_URI=bolt://neo4j:${NEO4J_BOLT_PORT}\n      - ENABLE_API_KEYS=${APOLLO_ENABLE_API_KEYS}\n    networks:\n      - ikg-network\n      - crisalid-front\n    profiles:\n      - apollo\nnetworks:\n  ikg-network:\n    driver: bridge\n  crisalid-front:\n    driver: bridge\n\nservices:\n  apollo:\n    image: crisalidesr/crisalid-apollo:latest\n    ports:\n      - ${APOLLO_API_PORT}:4000\n\nYour local SoVisu+ will call http://localhost:${APOLLO_API_PORT} (GraphQL endpoint /graphql).\n\n\n\n\nOnly the management UI port is exposed by default, but you can uncomment the AMQP port to allow external tools to connect:\n\n\ncrisalid-bus.yaml\n\nservices:\n  crisalid-bus:\n    image: rabbitmq:3-management\n    container_name: 'crisalid-bus'\n    environment:\n      - RABBITMQ_DEFAULT_USER=${CRISALID_BUS_USER}\n      - RABBITMQ_DEFAULT_PASS=${CRISALID_BUS_PASSWORD}\n      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit load_definitions \"${CRISALID_BUS_DEFINITIONS_FILE}\"\n    ports:\n      - \"${CRISALID_BUS_HTTP_PORT}:15672\"\n      - \"${CRISALID_BUS_AMQP_PORT}:5672\"\n    expose:\n      - \"${CRISALID_BUS_AMQP_PORT}\"\n    volumes:\n      - ./rabbitmq-data:/var/lib/rabbitmq\n      - ./rabbitmq-logs/:/var/log/rabbitmq\n      - ./definitions.json:${CRISALID_BUS_DEFINITIONS_FILE}:ro\n    healthcheck:\n      test: rabbitmq-diagnostics check_port_connectivity\n      interval: 1s\n      timeout: 3s\n      retries: 30\n    networks:\n      - crisalid-front\n      - crisalid-back\n    profiles:\n      - crisalid-bus\nnetworks:\n  crisalid-front:\n    driver: bridge\n  crisalid-back:\n    driver: bridge\n\nservices:\n  crisalid-bus:\n    image: rabbitmq:3-management\n    container_name: 'crisalid-bus'\n    environment:\n      - RABBITMQ_DEFAULT_USER=${CRISALID_BUS_USER}\n      - RABBITMQ_DEFAULT_PASS=${CRISALID_BUS_PASSWORD}\n      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit load_definitions \"${CRISALID_BUS_DEFINITIONS_FILE}\"\n    ports:\n      - \"${CRISALID_BUS_HTTP_PORT}:15672\"\n      - \"${CRISALID_BUS_AMQP_PORT}:5672\"\n    expose:\n      - \"${CRISALID_BUS_AMQP_PORT}\"\n\n\n\n\n\nReplace the sovisuplus profile with sovisuplus-db, which starts the DB and related services but not the SoVisu+ container itself.\nExample command:\ndocker compose \\\n  --profile cdb \\\n  --profile neo4j \\\n  --profile apollo \\\n  --profile crisalid-bus \\\n  --profile harvester \\\n  --profile ikg \\\n  --profile keycloak \\\n  --profile sovisuplus-db \\\n  up --remove-orphans\n\n\n\n\nStart your Next.js app on the host as usual (e.g., in the SoVisu+ repo):\nnpm run dev # for the main web gui\nnpm run dev:listener # for the backend listener\nMake sure your local env points to the Docker services. Typical variables (names vary by project):\n\nNEXT_PUBLIC_SUPPORTED_LOCALES=\"fr,en\"\n\nDATABASE_URL=\"postgresql://sovisuplus:sovisuplus_password@localhost:5432/sovisuplus?schema=public\"\n\nKEYCLOAK_CLIENT_ID=\"sovisuplus\"\nKEYCLOAK_CLIENT_SECRET=\"use-the-same-secret-as-in-docker-compose\"\nKEYCLOAK_ISSUER=\"http://keycloak.local:8080/realms/crisalid-inst\"\nNEXTAUTH_URL=\"http://sovisuplus.local:3000/api/auth\"\nNEXTAUTH_SECRET=\"use-a-secure-random-secret\"\n\nAMQP_USER=\"crisalid_bus_user\"\nAMQP_PASSWORD=\"use-the-same-password-as-in-docker-compose\"\nAMQP_HOST=\"localhost\"\nAMQP_PORT=\"5672\"\nAMQP_QUEUE_NAME=\"sovisuplus\"\nAMQP_EXCHANGE_NAME=\"graph\"\n\nGRAPHQL_ENDPOINT_ENABLED=\"true\"\nGRAPHQL_ENDPOINT_URL=\"http://localhost:4000/graphql\"\nGRAPHQL_API_KEY_ENABLED=\"false\"\nGRAPHQL_API_KEY=\"not-needed-in-dev\"\n\nPERSPECTIVES_ROLES_FILTER=\"author\"\nPUBLICATION_LIST_ROLES_FILTER=\"author\"\n\nORCID_URL=\"https://sandbox.orcid.org\"\nSOVISUPLUS_HOST=\"http://sovisuplus.local:3000\"\nORCID_SCOPES=\"/person/update\"\nORCID_CLIENT_ID=\"use-the-same-client-id--provided-by-orcid-as-in-docker-compose\"\nORCID_CLIENT_SECRET=\"use-the-same-client-secret-provided-by-orcid-as-in-docker-compose\"\nVisit SoVisu+ at:\nhttp://sovisuplus.local:3000"
  },
  {
    "objectID": "dev/dev-backend.html#goal",
    "href": "dev/dev-backend.html#goal",
    "title": "Using Docker Compose as Backend for Local Development",
    "section": "",
    "text": "Run all shared services (Neo4j, message bus, Keycloak, APIs, databases) in Docker, but run SoVisu+ on your host machine. To make this work, you must:\n\nMap the necessary service ports from containers to the host.\nUse a dedicated profile (e.g.¬†sovisuplus-db) to start only SoVisu+ backend services.\nPoint your local SoVisu+ to these services via env vars and /etc/hosts."
  },
  {
    "objectID": "dev/dev-backend.html#required-hostnames",
    "href": "dev/dev-backend.html#required-hostnames",
    "title": "Using Docker Compose as Backend for Local Development",
    "section": "",
    "text": "Add these entries to your /etc/hosts (if not already done in the main guide):\n127.0.0.1 sovisuplus.local\n127.0.0.1 keycloak.local\n\nSoVisu+ uses ORCID OAuth, which requires valid hostnames even for sandbox keys."
  },
  {
    "objectID": "dev/dev-backend.html#open-the-right-ports-in-compose",
    "href": "dev/dev-backend.html#open-the-right-ports-in-compose",
    "title": "Using Docker Compose as Backend for Local Development",
    "section": "",
    "text": "You‚Äôll run SoVisu+ locally, so your host needs to reach the containers. Make sure the following port mappings are enabled.\n\n\nUncomment the ports section so Postgres is reachable from your host:\n\n\nsovisuplus.yaml\n\nservices:\n  svp-db:\n    image: postgres:16\n    container_name: svp-db\n    restart: always\n    environment:\n      POSTGRES_USER: ${SVP_DB_USER}\n      POSTGRES_PASSWORD: ${SVP_DB_PASSWORD}\n      POSTGRES_DB: ${SVP_DB_NAME}\n    expose:\n      - 5432\n    ports:\n      - 5432:5432\n    volumes:\n      - ./postgres-data:/var/lib/postgresql/data\n    networks:\n      - svp-network\n    healthcheck:\n      test: ['CMD-SHELL', 'pg_isready -d ${SVP_DB_NAME} -U ${SVP_DB_USER}']\n      interval: 1s\n      timeout: 5s\n      retries: 10\n    command: [\"postgres\",\"-c\",\"max_connections=200\",\"-c\",\"superuser_reserved_connections=3\"]\n    profiles:\n      - sovisuplus\n      - sovisuplus-db\n\n  sovisuplus:\n    image: crisalidesr/sovisuplus:latest\n    container_name: sovisuplus\n    ports:\n      - 3000:3000\n      - 3001:3001\n    environment:\n      - DB_NAME=${SVP_DB_NAME}\n      - DB_USER=${SVP_DB_USER}\n      - DB_PASSWORD=${SVP_DB_PASSWORD}\n      - DB_HOST=svp-db\n      - DB_PORT=5432\n      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}\n      - AMQP_HOST=crisalid-bus\n      - AMQP_PORT=${CRISALID_BUS_AMQP_PORT}\n      - AMQP_USER=${CRISALID_BUS_USER}\n      - AMQP_PASSWORD=${CRISALID_BUS_PASSWORD}\n      - AMQP_QUEUE_NAME=${SVP_AMQP_QUEUE_NAME}\n      - AMQP_EXCHANGE_NAME=${SVP_AMQP_EXCHANGE_NAME}\n      - GRAPHQL_ENDPOINT_ENABLED=${GRAPHQL_ENDPOINT_ENABLED}\n      - GRAPHQL_ENDPOINT_URL=http://apollo:${APOLLO_API_PORT}/graphql\n      - GRAPHQL_API_KEY_ENABLED=${GRAPHQL_API_KEY_ENABLED}\n      - KEYCLOAK_CLIENT_ID=sovisuplus\n      - KEYCLOAK_CLIENT_SECRET=${SOVISUPLUS_KEYCLOAK_CLIENT_SECRET}\n      - KEYCLOAK_ADDR=${KEYCLOAK_SCHEME}://${KEYCLOAK_HOST}:${KEYCLOAK_PORT}\n      - KEYCLOAK_REALM=${KEYCLOAK_REALM}\n      - APP_URL=${SOVISUPLUS_SCHEME}://${SOVISUPLUS_HOST}:${SOVISUPLUS_PORT}\n      - ORCID_URL=${ORCID_URL}\n      - ORCID_SCOPES=${ORCID_SCOPES}\n      - ORCID_CLIENT_ID=${ORCID_CLIENT_ID}\n      - ORCID_CLIENT_SECRET=${ORCID_CLIENT_SECRET}\n      - SOVISUPLUS_HOST=${SOVISUPLUS_SCHEME}://${SOVISUPLUS_HOST}:${SOVISUPLUS_PORT}\n    depends_on:\n      svp-db:\n        condition: service_healthy\n      crisalid-bus:\n        condition: service_healthy\n    networks:\n      - svp-network\n      - crisalid-front\n    profiles:\n      - sovisuplus\n\nnetworks:\n  svp-network:\n    driver: bridge\n  crisalid-front:\n    driver: bridge\n\nservices:\n  svp-db:\n    image: postgres:16\n    container_name: svp-db\n    restart: always\n    environment:\n      POSTGRES_USER: ${SVP_DB_USER}\n      POSTGRES_PASSWORD: ${SVP_DB_PASSWORD}\n      POSTGRES_DB: ${SVP_DB_NAME}\n    expose:\n      - 5432\n    ports:\n      - 5432:5432\n\n\n\nEnsure the public mapping is present (it typically is already because Apollo graphql GUI is one of the main user interfaces):\n\n\napollo.yaml\n\nservices:\n  apollo:\n    image: crisalidesr/crisalid-apollo:latest\n    ports:\n      - ${APOLLO_API_PORT}:4000\n    depends_on:\n      neo4j:\n        condition: service_healthy\n    environment:\n      - APP_ENV=DEV\n      - NEO4J_URI=bolt://neo4j:${NEO4J_BOLT_PORT}\n      - ENABLE_API_KEYS=${APOLLO_ENABLE_API_KEYS}\n    networks:\n      - ikg-network\n      - crisalid-front\n    profiles:\n      - apollo\nnetworks:\n  ikg-network:\n    driver: bridge\n  crisalid-front:\n    driver: bridge\n\nservices:\n  apollo:\n    image: crisalidesr/crisalid-apollo:latest\n    ports:\n      - ${APOLLO_API_PORT}:4000\n\nYour local SoVisu+ will call http://localhost:${APOLLO_API_PORT} (GraphQL endpoint /graphql).\n\n\n\n\nOnly the management UI port is exposed by default, but you can uncomment the AMQP port to allow external tools to connect:\n\n\ncrisalid-bus.yaml\n\nservices:\n  crisalid-bus:\n    image: rabbitmq:3-management\n    container_name: 'crisalid-bus'\n    environment:\n      - RABBITMQ_DEFAULT_USER=${CRISALID_BUS_USER}\n      - RABBITMQ_DEFAULT_PASS=${CRISALID_BUS_PASSWORD}\n      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit load_definitions \"${CRISALID_BUS_DEFINITIONS_FILE}\"\n    ports:\n      - \"${CRISALID_BUS_HTTP_PORT}:15672\"\n      - \"${CRISALID_BUS_AMQP_PORT}:5672\"\n    expose:\n      - \"${CRISALID_BUS_AMQP_PORT}\"\n    volumes:\n      - ./rabbitmq-data:/var/lib/rabbitmq\n      - ./rabbitmq-logs/:/var/log/rabbitmq\n      - ./definitions.json:${CRISALID_BUS_DEFINITIONS_FILE}:ro\n    healthcheck:\n      test: rabbitmq-diagnostics check_port_connectivity\n      interval: 1s\n      timeout: 3s\n      retries: 30\n    networks:\n      - crisalid-front\n      - crisalid-back\n    profiles:\n      - crisalid-bus\nnetworks:\n  crisalid-front:\n    driver: bridge\n  crisalid-back:\n    driver: bridge\n\nservices:\n  crisalid-bus:\n    image: rabbitmq:3-management\n    container_name: 'crisalid-bus'\n    environment:\n      - RABBITMQ_DEFAULT_USER=${CRISALID_BUS_USER}\n      - RABBITMQ_DEFAULT_PASS=${CRISALID_BUS_PASSWORD}\n      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit load_definitions \"${CRISALID_BUS_DEFINITIONS_FILE}\"\n    ports:\n      - \"${CRISALID_BUS_HTTP_PORT}:15672\"\n      - \"${CRISALID_BUS_AMQP_PORT}:5672\"\n    expose:\n      - \"${CRISALID_BUS_AMQP_PORT}\""
  },
  {
    "objectID": "dev/dev-backend.html#use-the-backend-only-profile",
    "href": "dev/dev-backend.html#use-the-backend-only-profile",
    "title": "Using Docker Compose as Backend for Local Development",
    "section": "",
    "text": "Replace the sovisuplus profile with sovisuplus-db, which starts the DB and related services but not the SoVisu+ container itself.\nExample command:\ndocker compose \\\n  --profile cdb \\\n  --profile neo4j \\\n  --profile apollo \\\n  --profile crisalid-bus \\\n  --profile harvester \\\n  --profile ikg \\\n  --profile keycloak \\\n  --profile sovisuplus-db \\\n  up --remove-orphans"
  },
  {
    "objectID": "dev/dev-backend.html#run-sovisu-locally",
    "href": "dev/dev-backend.html#run-sovisu-locally",
    "title": "Using Docker Compose as Backend for Local Development",
    "section": "",
    "text": "Start your Next.js app on the host as usual (e.g., in the SoVisu+ repo):\nnpm run dev # for the main web gui\nnpm run dev:listener # for the backend listener\nMake sure your local env points to the Docker services. Typical variables (names vary by project):\n\nNEXT_PUBLIC_SUPPORTED_LOCALES=\"fr,en\"\n\nDATABASE_URL=\"postgresql://sovisuplus:sovisuplus_password@localhost:5432/sovisuplus?schema=public\"\n\nKEYCLOAK_CLIENT_ID=\"sovisuplus\"\nKEYCLOAK_CLIENT_SECRET=\"use-the-same-secret-as-in-docker-compose\"\nKEYCLOAK_ISSUER=\"http://keycloak.local:8080/realms/crisalid-inst\"\nNEXTAUTH_URL=\"http://sovisuplus.local:3000/api/auth\"\nNEXTAUTH_SECRET=\"use-a-secure-random-secret\"\n\nAMQP_USER=\"crisalid_bus_user\"\nAMQP_PASSWORD=\"use-the-same-password-as-in-docker-compose\"\nAMQP_HOST=\"localhost\"\nAMQP_PORT=\"5672\"\nAMQP_QUEUE_NAME=\"sovisuplus\"\nAMQP_EXCHANGE_NAME=\"graph\"\n\nGRAPHQL_ENDPOINT_ENABLED=\"true\"\nGRAPHQL_ENDPOINT_URL=\"http://localhost:4000/graphql\"\nGRAPHQL_API_KEY_ENABLED=\"false\"\nGRAPHQL_API_KEY=\"not-needed-in-dev\"\n\nPERSPECTIVES_ROLES_FILTER=\"author\"\nPUBLICATION_LIST_ROLES_FILTER=\"author\"\n\nORCID_URL=\"https://sandbox.orcid.org\"\nSOVISUPLUS_HOST=\"http://sovisuplus.local:3000\"\nORCID_SCOPES=\"/person/update\"\nORCID_CLIENT_ID=\"use-the-same-client-id--provided-by-orcid-as-in-docker-compose\"\nORCID_CLIENT_SECRET=\"use-the-same-client-secret-provided-by-orcid-as-in-docker-compose\"\nVisit SoVisu+ at:\nhttp://sovisuplus.local:3000"
  },
  {
    "objectID": "dev/backup-restore-with-dc.html",
    "href": "dev/backup-restore-with-dc.html",
    "title": "Data backup and restoration with Docker Compose",
    "section": "",
    "text": "Quick recipes to backup and restore services in the CRISalid Docker Compose stack."
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#full-backup",
    "href": "dev/backup-restore-with-dc.html#full-backup",
    "title": "Data backup and restoration with Docker Compose",
    "section": "üì¶ Full backup",
    "text": "üì¶ Full backup\n\nRecommended: stop Neo4j before a backup to ensure a clean snapshot.\n\nCreate a compressed archive of the key data directories (preserve numeric ownership for container UID/GID 7474):\nsudo tar --numeric-owner -czvf neo4j-full-$(date +%F).tar.gz \\\n  data import backups plugins"
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#restore-from-a-backup-archive",
    "href": "dev/backup-restore-with-dc.html#restore-from-a-backup-archive",
    "title": "Data backup and restoration with Docker Compose",
    "section": "‚ôªÔ∏è Restore from a backup archive",
    "text": "‚ôªÔ∏è Restore from a backup archive\n\nImportant: Stop Neo4j before restoring files.\n\n\nExtract the archive to the Neo4j docker directory:\n\ntar -xzvf neo4j-data-20250908.tar.gz \\\n  -C ~/.../crisalid-deployment/docker/neo4j\n\nEnsure directory ownership matches the container user (UID/GID 7474):\n\ncd ~/code/crisalid-deployment/docker/neo4j\nsudo chown -R 7474:7474 data import backups plugins\n\nStart Neo4j again (alone or with other services):\n\ndocker compose --profile neo4j up -d neo4j\n\n(Optional) Check logs:\n\ndocker compose logs -f neo4j"
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#make-a-sql-dump",
    "href": "dev/backup-restore-with-dc.html#make-a-sql-dump",
    "title": "Data backup and restoration with Docker Compose",
    "section": "Make a SQL dump",
    "text": "Make a SQL dump\nWith a running Docker Compose stack (svp-db container):\n# optional: export env if not already loaded\nexport SVP_DB_NAME=${SVP_DB_NAME}\nexport SVP_DB_USER=${SVP_DB_USER}\n\ndocker compose exec -T svp-db \\\n  pg_dump -U \"$SVP_DB_USER\" -d \"$SVP_DB_NAME\" \\\n    --format=plain \\\n    --no-owner --no-privileges \\\n    --clean --if-exists \\\n  &gt; \"sovisuplus-$(date +%F).sql\""
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#restore-into-docker-same-svp-db",
    "href": "dev/backup-restore-with-dc.html#restore-into-docker-same-svp-db",
    "title": "Data backup and restoration with Docker Compose",
    "section": "Restore into Docker (same svp-db)",
    "text": "Restore into Docker (same svp-db)\ncat sovisuplus-YYYY-MM-DD.sql | \\\n  docker compose exec -T svp-db psql -U \"$SVP_DB_USER\" -d \"$SVP_DB_NAME\""
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#restore-into-local-postgres-on-your-machine",
    "href": "dev/backup-restore-with-dc.html#restore-into-local-postgres-on-your-machine",
    "title": "Data backup and restoration with Docker Compose",
    "section": "Restore into local Postgres (on your machine)",
    "text": "Restore into local Postgres (on your machine)\nPGPASSWORD=\"$SVP_DB_PASSWORD\" psql \\\n  -h localhost -p 5432 -U \"$SVP_DB_USER\" -d \"$SVP_DB_NAME\" \\\n  -f sovisuplus-YYYY-MM-DD.sql"
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#make-a-sql-dump-1",
    "href": "dev/backup-restore-with-dc.html#make-a-sql-dump-1",
    "title": "Data backup and restoration with Docker Compose",
    "section": "Make a SQL dump",
    "text": "Make a SQL dump\nexport HARVESTER_DB_NAME=${HARVESTER_DB_NAME}\nexport HARVESTER_DB_USER=${HARVESTER_DB_USER}\n\ndocker compose exec -T harvester-db \\\n  pg_dump -U \"$HARVESTER_DB_USER\" -d \"$HARVESTER_DB_NAME\" \\\n    --format=plain \\\n    --no-owner --no-privileges \\\n    --clean --if-exists \\\n  &gt; \"harvester-$(date +%F).sql\""
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#restore-into-docker-harvester-db",
    "href": "dev/backup-restore-with-dc.html#restore-into-docker-harvester-db",
    "title": "Data backup and restoration with Docker Compose",
    "section": "Restore into Docker (harvester-db)",
    "text": "Restore into Docker (harvester-db)\ncat harvester-YYYY-MM-DD.sql | \\\n  docker compose exec -T harvester-db psql -U \"$HARVESTER_DB_USER\" -d \"$HARVESTER_DB_NAME\""
  },
  {
    "objectID": "dev/backup-restore-with-dc.html#restore-into-local-postgres",
    "href": "dev/backup-restore-with-dc.html#restore-into-local-postgres",
    "title": "Data backup and restoration with Docker Compose",
    "section": "Restore into local Postgres",
    "text": "Restore into local Postgres\nCreate target DB/user on your host if needed, then:\nPGPASSWORD=\"$HARVESTER_DB_PASSWORD\" psql \\\n  -h localhost -p 5432 -U \"$HARVESTER_DB_USER\" -d \"$HARVESTER_DB_NAME\" \\\n  -f harvester-YYYY-MM-DD.sql"
  },
  {
    "objectID": "dev/docker-compose.html",
    "href": "dev/docker-compose.html",
    "title": "Docker Compose deployment",
    "section": "",
    "text": "‚ö†Ô∏è Warning: Do not deploy this setup to production. This configuration is meant solely for local development and testing."
  },
  {
    "objectID": "dev/docker-compose.html#choosing-the-components",
    "href": "dev/docker-compose.html#choosing-the-components",
    "title": "Docker Compose deployment",
    "section": "üîç Choosing the Components",
    "text": "üîç Choosing the Components\nBefore you start, review the components available in map/components.qmd and decide which ones you need.\nThe main Compose file (docker/docker-compose.yaml) is modular. It uses the include directive and profiles to enable only selected components.\n\n\nMain docker-compose.yaml\n\nname: crisalid\n\ninclude:\n  - path: ./neo4j/neo4j.yaml\n    env_file: ./neo4j/.env\n    project_directory: ./neo4j\n  - path: ./apollo/apollo.yaml\n    env_file: ./apollo/.env\n    project_directory: ./apollo\n  - path: ./crisalid-bus/crisalid-bus.yaml\n    env_file: ./crisalid-bus/.env\n    project_directory: ./crisalid-bus\n  - path: ./harvester/harvester.yaml\n    env_file: ./harvester/.env\n    project_directory: ./harvester\n  - path: ./ikg/ikg.yaml\n    env_file: ./ikg/.env\n    project_directory: ./ikg\n  - path: ./cdb/cdb.yaml\n    env_file: ./cdb/.env\n    project_directory: ./cdb\n  - path: ./sovisuplus/sovisuplus.yaml\n    env_file: ./sovisuplus/.env\n    project_directory: ./sovisuplus\n  - path: ./keycloak/keycloak.yaml\n    env_file: ./keycloak/.env\n    project_directory: ./keycloak\n\nFor example:\ndocker compose \\\n  --profile neo4j \\\n  --profile apollo \\\n  --profile crisalid-bus \\\n  --profile harvester \\\n  --profile ikg \\\n  --profile cdb \\\n  --profile keycloak \\\n  --profile sovisuplus \\\n  up"
  },
  {
    "objectID": "dev/docker-compose.html#preparation-steps",
    "href": "dev/docker-compose.html#preparation-steps",
    "title": "Docker Compose deployment",
    "section": "üß∞ Preparation Steps",
    "text": "üß∞ Preparation Steps\n\n1. üßæ .env Files\nEach directory under docker/ (e.g.¬†apollo, crisalid-bus, ikg, neo4j, cdb, harvester) has its own .env.sample file.\n\nCopy each .env.sample to .env\nFill in appropriate values (hostnames, ports, secrets, etc.)\nThe main docker/.env.sample includes values used by multiple components (like RabbitMQ or Neo4j credentials)\n\n\nIf you plan to connect the CRISalid Directory Bridge (cdb) to your institutional LDAP, make sure to set:\nLDAP_HOST=\nLDAP_BIND_DN=\nLDAP_BIND_PASSWORD=\n\n\n\n2. üîß Configure CRISalid Bus\nThis script reads the .env values and generates the RabbitMQ definitions.json file (exchanges, queues, admin user, etc.).\n./docker/configure_crisalid_bus.sh\n\n\n3. üîß Configure CRISalid Directory Bridge (CDB)\nThis script clones the DAGs and runs the Airflow initialization:\n./docker/configure_cdb.sh\n‚ÑπÔ∏è In dev, Airflow GUI admin credentials are set to admin:admin.\nAfter running the script, if you intend to use the CSV mode for structures and people (instead of LDAP), place your data files in:\ndocker/cdb/data/\n‚îú‚îÄ‚îÄ structure.csv\n‚îî‚îÄ‚îÄ people.csv\nSample CSVs:\n\ndocker/cdb/dags/data\n\nFull documentation (in French):\n\nLaboratories\nResearchers\n\n\n\n\n4. üîë Configure Keycloak\nKeycloak is handling authentication within the system. Multiple client applications (such as Sovisu+) can share the same authentication realm. To set up Keycloak in this environment, follow these steps:\n\nGlobal .env Configuration\n\nIn the global .env file, you will find the shared Keycloak configuration variables, such as the realm name ( KEYCLOAK_REALM) and the client secrets (SOVISUPLUS_KEYCLOAK_CLIENT_SECRET). The KEYCLOAK_REALM can be customized ( e.g., crisalid-my-university) for readability.\nExample:\nKEYCLOAK_REALM=crisalid-inst\nSOVISUPLUS_KEYCLOAK_CLIENT_SECRET=MY-SECRET-VALUE\n\nKeycloak Configuration Script\n\nRun the ./configure_keycloak.sh script. This will create the required configuration file from the template ( docker/keycloak/config/crisalid-inst.json.template).\n\nCustomizing Keycloak .env Settings\n\nThe docker/keycloak/.env.sample file provides the environment settings for Keycloak, such as the admin credentials and database configurations. Copy the sample file to .env and modify the settings as needed.\nKEYCLOAK_ADMIN=admin\nKEYCLOAK_ADMIN_PASSWORD=admin\nKEYCLOAK_DB_VENDOR=postgres\nKEYCLOAK_DB_HOST=keycloak-db\nKEYCLOAK_DB_PORT=5432\nKEYCLOAK_DB_NAME=keycloak\nKEYCLOAK_DB_USER=keycloak\nKEYCLOAK_DB_PASSWORD=keycloak\n\n\n5. Define specific URIs in /etc/hosts\nTo ensure that Sovisu+ and Keycloak can be accessed correctly, you need to define specific URIs in your /etc/hosts file. This is necessary because Sovisu+ uses OAuth2 with ORCID, which requires a specific hostname even to deliver ‚Äúsandbox‚Äù keys.\n# Add these lines to your /etc/hosts file\n127.0.0.1 sovisuplus.local\n127.0.0.1 keycloak.local"
  },
  {
    "objectID": "dev/docker-compose.html#communication-with-host-machine",
    "href": "dev/docker-compose.html#communication-with-host-machine",
    "title": "Docker Compose deployment",
    "section": "üîå Communication with Host Machine",
    "text": "üîå Communication with Host Machine\nIf you want to connect external tools (on your host) to the containers, open the necessary ports.\nFor example, to expose RabbitMQ‚Äôs AMQP port on the host machine, edit docker/crisalid-bus/crisalid-bus.yaml and uncomment the 2nd ports line:\nports:\n  - \"${CRISALID_BUS_HTTP_PORT}:15672\"\n#  - \"${CRISALID_BUS_AMQP_PORT}:5672\"\nexpose:\n  - \"${CRISALID_BUS_AMQP_PORT}\""
  },
  {
    "objectID": "dev/docker-compose.html#resetting-containers",
    "href": "dev/docker-compose.html#resetting-containers",
    "title": "Docker Compose deployment",
    "section": "‚ôªÔ∏è Resetting Containers",
    "text": "‚ôªÔ∏è Resetting Containers\nTo stop and delete containers + volumes for one profile:\ndocker compose --profile cdb down --volumes\nTo also delete images:\ndocker compose --profile cdb down --volumes --rmi all\nTo ensure volumes are removed, you can also run:\ndocker volume rm postgres-db-volume redis-db-volume data-versioning-redis-volume\ndocker volume rm keycloak_postgres_data\ndocker volume rm svp-db-volume\ndocker volume rm crisalid-bus-volume\ndocker volume rm neo4j-data-volume neo4j-logs-volume neo4j-import-volume neo4j-plugins-volume neo4j-backups-volume"
  },
  {
    "objectID": "dev/docker-compose.html#starting-the-services",
    "href": "dev/docker-compose.html#starting-the-services",
    "title": "Docker Compose deployment",
    "section": "üöÄ Starting the Services",
    "text": "üöÄ Starting the Services\nTo start the services, run:\ndocker compose --profile neo4j --profile apollo --profile crisalid-bus --profile harvester --profile ikg --profile cdb --profile keycloak --profile sovisuplus up\nThis command will start the selected components in the background. You can add or remove profiles as needed."
  },
  {
    "objectID": "dev/docker-compose.html#next-steps",
    "href": "dev/docker-compose.html#next-steps",
    "title": "Docker Compose deployment",
    "section": "‚úÖ Next Steps",
    "text": "‚úÖ Next Steps\nOnce your services are up, follow the component-specific instructions in each section of the documentation. You can now:\n\nAccess the CRISalid Directory Bridge (CDB) UI at http://localhost:8081 (Airflow) and trigger DAGs to import structures and people\nAccess the Neo4j UI at http://localhost:7474 and explore the graph database\nAccess the RabbitMQ UI at http://localhost:15672 with credentials from docker/.env and monitor messages\nAccess SVP Harvester at http://localhost:8000 to monitor publication harvesting\nAccess the Apollo GraphQL UI at http://localhost:4000/graphql to explore the API through Apollo GUI\nAccess Keycloak at http://keycloak.local:8080 to manage users and roles\nAccess SoVisu+ at http://sovisuplus.local:3000 to visualize your data\nStart connecting other CRISalid modules from the host machine\n\nüß≠ Back to Development Index"
  }
]